{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48155153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tsfresh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# keras goodies\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv1D, Dropout, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dd9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows_Creation():\n",
    "    base_df = pd.DataFrame()\n",
    "\n",
    "    clean_data_folder = \"./Data/Clean\"\n",
    "\n",
    "    for filename in os.listdir(clean_data_folder):\n",
    "        full_path = f\"{clean_data_folder}/{filename}\"\n",
    " \n",
    "        new_df = pd.read_csv(full_path)\n",
    "    \n",
    "        # merge into the base DataFrame\n",
    "        base_df = pd.concat([base_df, new_df])\n",
    "    \n",
    "    # not NaN\n",
    "    base_df = base_df[base_df['accel_x'].notna()]\n",
    "    base_df = base_df[base_df['accel_y'].notna()]\n",
    "    base_df = base_df[base_df['accel_z'].notna()]\n",
    "    base_df = base_df[base_df['gyro_x'].notna()]\n",
    "    base_df = base_df[base_df['gyro_y'].notna()]\n",
    "    base_df = base_df[base_df['gyro_z'].notna()]\n",
    "    \n",
    "    base_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    example_recording = base_df[base_df.activity_code == 1]\n",
    "    window_size = 50 # 50 datapoints for the window size, which, at 25Hz, means 2 seconds\n",
    "    step_size = 25 # this is 50% overlap\n",
    "\n",
    "    window_number = 0 # start a counter at 0 to keep track of the window number\n",
    "\n",
    "    large_enough_windows = [window for window in example_recording.rolling(window=window_size, min_periods=window_size) if len(window) == window_size]\n",
    "\n",
    "    overlapping_windows = large_enough_windows[::step_size]\n",
    "    for window in overlapping_windows:\n",
    "        window.loc[:, 'window_id'] = window_number\n",
    "        window_number += 1\n",
    "    \n",
    "    final_sliding_windows = pd.concat(overlapping_windows).reset_index(drop=True)\n",
    "    columns_of_interest = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "    \n",
    "    feature_list = []\n",
    "    for col in columns_of_interest:\n",
    "        new_features = tsfresh.extract_features(timeseries_container=final_sliding_windows, column_id='window_id',\n",
    "                            column_value=col, default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters())\n",
    "        feature_list.append(new_features)\n",
    "    feature_list = pd.concat(feature_list, axis=1)\n",
    "    \n",
    "    window_number = 0 # start a counter at 0 to keep track of the window number\n",
    "\n",
    "    all_overlapping_windows = []\n",
    "\n",
    "    for rid, group in base_df.groupby(\"recording_id\"):\n",
    "#         print(f\"Processing rid = {rid}\", end=' ')\n",
    "\n",
    "        large_enough_windows = [window for window in group.rolling(window=window_size, min_periods=window_size) if len(window) == window_size]\n",
    "\n",
    "        overlapping_windows = large_enough_windows[::step_size] \n",
    "\n",
    "        # then we will append a window ID to each window\n",
    "        for window in overlapping_windows:\n",
    "            window.loc[:, 'window_id'] = window_number\n",
    "            window_number += 1\n",
    "\n",
    "        # ??? some sind void?\n",
    "        if len(overlapping_windows) == 0:\n",
    "            continue\n",
    "\n",
    "        all_overlapping_windows.append(pd.concat(overlapping_windows).reset_index(drop=True))\n",
    "        \n",
    "    final_sliding_windows = pd.concat(all_overlapping_windows).reset_index(drop=True)\n",
    "    \n",
    "    # now extract all features\n",
    "    feature_list = []\n",
    "    for col in columns_of_interest:\n",
    "        new_features = tsfresh.extract_features(timeseries_container=final_sliding_windows, column_id='window_id',\n",
    "                            column_value=col, default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters())\n",
    "        feature_list.append(new_features)\n",
    "    feature_list = pd.concat(feature_list, axis=1)\n",
    "    \n",
    "    final_sliding_windows.groupby(\"window_id\")[['activity_type']].agg(np.min)\n",
    "    \n",
    "    return final_sliding_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df81aa0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_sliding_windows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30164\\910585190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     19\u001b[0m \u001b[0mcolumns_of_interest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accel_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accel_y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accel_z'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gyro_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gyro_y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gyro_z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mwindow_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_sliding_windows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'window_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"window_id = {window_id}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_sliding_windows' is not defined"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "class_labels = {\n",
    "     'Climbing stairs': 0,\n",
    "     'Descending stairs': 0,\n",
    "     'Desk work': 2,\n",
    "     'Sitting': 3,\n",
    "     'Sitting bent backward': 4,\n",
    "     'Sitting bent forward': 5,\n",
    "     'Standing': 6,\n",
    "     'Lying down left': 7,\n",
    "     'Lying down on back': 8,\n",
    "     'Lying down on stomach': 9,\n",
    "     'Lying down right': 10,\n",
    "     'Movement': 11,\n",
    "     'Running': 12,\n",
    "     'Walking at normal speed': 0\n",
    "}\n",
    "columns_of_interest = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "for window_id, group in final_sliding_windows.groupby('window_id'):\n",
    "    print(f\"window_id = {window_id}\")\n",
    "    \n",
    "    shape = group[columns_of_interest].values.shape\n",
    "    print(f\"shape = {shape}\")\n",
    "    \n",
    "    X.append(group[columns_of_interest].values)\n",
    "    y.append(class_labels[group[\"activity_type\"].values[0]])\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "print(f\"X shape = {X.shape}\")\n",
    "print(f\"y shape = {y.shape}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, train_size=0.8)\n",
    "\n",
    "y_train = np.asarray(pd.get_dummies(y_train), dtype=np.float32)\n",
    "y_test = np.asarray(pd.get_dummies(y_test), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e66358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
